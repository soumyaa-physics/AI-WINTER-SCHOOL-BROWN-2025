{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyaa-physics/AI-WINTER-SCHOOL-BROWN-2025/blob/main/2025_GNN4ParticlePhysics_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This exercise has two stages. The first one to explore the power of GNNs on classification task and the second for clustering i.e., grouping of energy deposits on the detector subsystems (a rather novel and challenging topic)\n",
        "\n",
        "We will be using PyTorch for the development and training for the AI models\n",
        "\n"
      ],
      "metadata": {
        "id": "d-wkWPqeiiZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jet type identification using AI (CNN-2D vs. GNNs)\n",
        "More info:\n",
        "* https://opendata.cern.ch/record/15013\n",
        "* https://gitlab.cern.ch/atlas/ATLAS-top-tagging-open-data\n"
      ],
      "metadata": {
        "id": "MtDFUIZGjRyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will utilize two different neural network architectures:\n",
        "- **Convolutional Neural Networks (CNNs)**: These are well-suited for image-like data where spatial relationships are essential.\n",
        "- **Graph Neural Networks (GNNs)**: These excel at learning from data represented as graphs, making them ideal for particle-level information where constituents of jets can be treated as graph nodes.\n",
        "\n",
        "The key steps in this notebook include:\n",
        "1. **Data Loading and Preprocessing**\n",
        "2. **Exploratory Data Analysis (EDA)**\n",
        "3. **Model Definition and Training**\n",
        "4. **Evaluation (ROC Curves)**"
      ],
      "metadata": {
        "id": "yjn5mmFdxHV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Load the dataset\n",
        "\n",
        "We will load the dataset using the `h5py` library and separate jets into signal and background categories based on their labels.\n",
        "\n",
        "We also access only the necessary information from the input file\n",
        "\n",
        "e.g., fjet_clus_pt, etc..\n",
        "\n",
        "The dataset contains information about jets in high-energy particle collisions. Each jet is composed of multiple constituents with the following features:\n",
        "- **Transverse momentum ($p_T$)**: Describes the momentum of the jet in the transverse plane.\n",
        "- **Pseudorapidity ($\\eta$)**: Represents the angle of the jet relative to the beam axis.\n",
        "- **Azimuthal angle ($\\phi$)**: Represents the angle of the jet in the transverse plane (i.e., azimuthal angle).\n",
        "- **Energy ($E$)**: The total energy of the jet.\n",
        "- **labels:** Binary labels indicating whether a jet is from the background class (0) or the signal class (1)."
      ],
      "metadata": {
        "id": "iNfucBCjjhPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Include the necessary libraries\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ibePWzB08Q33"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "winter_school_drive = \"AI WINTER SCHOOL-SOUMYAA/\"\n",
        "local_path = '/content/drive/My Drive/AI WINTER SCHOOL-SOUMYAA/'\n",
        "# top_level_path = '/content/drive/Shared drives/AI Winter School (Brown Physics CFPU 2025)/'"
      ],
      "metadata": {
        "id": "FDBnmgkI8Nsp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7fa3fc-f0b4-42d4-dd30-b6b1d04464f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the module-specific path\n",
        "module_path = 'Module 2/ATLAS_TopTagging_OpenData_Small.h5'"
      ],
      "metadata": {
        "id": "a4Vtlc3P8HFV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_path = local_path+module_path"
      ],
      "metadata": {
        "id": "KBnRAC_B8U-A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(full_path, 'r') as h5_file:\n",
        "    pt = np.array(h5_file['fjet_clus_pt'])\n",
        "    eta = np.array(h5_file['fjet_clus_eta'])\n",
        "    phi = np.array(h5_file['fjet_clus_phi'])\n",
        "    energy = np.array(h5_file['fjet_clus_E'])\n",
        "    labels = np.array(h5_file['labels'])\n",
        "    weights = np.array(h5_file['training_weights'])"
      ],
      "metadata": {
        "id": "h3WFSoFPjtbw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize constituent energy by the total jet energy\n",
        "total_jet_energy = np.sum(energy, axis=1, keepdims=True)\n",
        "normalized_energy = energy / total_jet_energy"
      ],
      "metadata": {
        "id": "EtHJ7Xdo-eoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a binary classification problem and we want to check how balanced are the two classes"
      ],
      "metadata": {
        "id": "l6vI2pxJkBbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class balance plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(labels, bins=2, edgecolor='black', alpha=0.7)\n",
        "plt.xticks([0, 1], ['Background (0)', 'Signal (1)'])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Class Balance in the Dataset')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kpv4uXuJkIAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Filtering Constituents\n",
        "* Constituents with non-positive transverse momentum (pt) or energy are considered unphysical and are removed.\n",
        "* This step ensures that only valid physical data is processed further."
      ],
      "metadata": {
        "id": "81z2AEovkaca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distributions of Physical Quantities**\n",
        "\n",
        "Before training the models, it's essential to understand the input data. We will plot the distributions of the following quantities for both signal and background jets.\n",
        "\n",
        "By visualizing these distributions, we can gain info about the differences between signal and background jets."
      ],
      "metadata": {
        "id": "IM01O3lQxe9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate signal and background based on labels\n",
        "signal_mask = labels == 1\n",
        "background_mask = labels == 0\n",
        "\n",
        "# Plot distributions for signal and background\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# pT distribution\n",
        "axs[0, 0].hist(pt[signal_mask].flatten(), bins=50, range=(0, 500), alpha=0.7, label='Signal', color='blue')\n",
        "axs[0, 0].hist(pt[background_mask].flatten(), bins=50, range=(0, 500), alpha=0.7, label='Background', color='red')\n",
        "axs[0, 0].set_title('Log Transverse Momentum ($p_T$) Distribution')\n",
        "axs[0, 0].set_xlabel('$p_T$ [GeV]')\n",
        "axs[0, 0].set_ylabel('Frequency')\n",
        "axs[0, 0].set_yscale('log')\n",
        "axs[0, 0].legend()\n",
        "\n",
        "# Eta distribution\n",
        "axs[0, 1].hist(eta[signal_mask].flatten(), bins=50, range=(-5, 5), alpha=0.7, label='Signal', color='blue')\n",
        "axs[0, 1].hist(eta[background_mask].flatten(), bins=50, range=(-5, 5), alpha=0.7, label='Background', color='red')\n",
        "axs[0, 1].set_title('Pseudorapidity ($\\eta$) Distribution')\n",
        "axs[0, 1].set_xlabel('$\\eta$')\n",
        "axs[0, 1].set_ylabel('Frequency')\n",
        "axs[0, 1].legend()\n",
        "\n",
        "# Phi distribution\n",
        "axs[1, 0].hist(phi[signal_mask].flatten(), bins=50, range=(-np.pi, np.pi), alpha=0.7, label='Signal', color='blue')\n",
        "axs[1, 0].hist(phi[background_mask].flatten(), bins=50, range=(-np.pi, np.pi), alpha=0.7, label='Background', color='red')\n",
        "axs[1, 0].set_title('Azimuthal Angle ($\\phi$) Distribution')\n",
        "axs[1, 0].set_xlabel('$\\phi$ [rad]')\n",
        "axs[1, 0].set_ylabel('Frequency')\n",
        "axs[1, 0].legend()\n",
        "\n",
        "# Energy distribution\n",
        "axs[1, 1].hist(normalized_energy[signal_mask].flatten(), bins=50, range=(0, 1), alpha=0.7, label='Signal', color='blue')\n",
        "axs[1, 1].hist(normalized_energy[background_mask].flatten(), bins=50, range=(0, 1), alpha=0.7, label='Background', color='red')\n",
        "axs[1, 1].set_title('Log Energy ($E$) Distribution')\n",
        "axs[1, 1].set_xlabel('Energy [GeV]')\n",
        "axs[1, 1].set_ylabel('Frequency')\n",
        "axs[1, 1].set_yscale('log')\n",
        "axs[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z2_s83JeyF8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (pt > 0) & (energy > 0)\n",
        "pt_filtered = np.where(mask, pt, 0)\n",
        "eta_filtered = np.where(mask, eta, 0)\n",
        "phi_filtered = np.where(mask, phi, 0)\n",
        "energy_filtered = np.where(mask, normalized_energy, 0)\n",
        "\n",
        "\n",
        "# Define max_constits before using it in the CNN model\n",
        "max_constits = 80  # Maximum number of constituents to consider for each jet"
      ],
      "metadata": {
        "id": "EJP0_T7Kku1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The remaining steps are specific to CNN-2D**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TjgHVAICk2dY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Preprocessing\n",
        "* Preprocessing involves three main tasks:\n",
        "\t1.\tCentering: The η and φ values are shifted so that the leading constituent (the one with the highest transverse momentum) is positioned at (0, 0) in the η-φ plane.\n",
        "\t2.\tWrapping φ values: The φ values are wrapped into the range [−π, π], ensuring circular symmetry.\n",
        "\t3.\tEnergy Normalization: The energy of each constituent is divided by the total energy of the jet, resulting in values between 0 and 1.\n",
        "* The maximum number of constituents per jet is limited to *max_constits = 80*, and jets with fewer constituents are padded with zeros."
      ],
      "metadata": {
        "id": "dpNglSCRkzyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(pt, eta, phi, energy, max_constits=80):\n",
        "    num_jets = len(pt)\n",
        "    pt_padded = np.zeros((num_jets, max_constits))\n",
        "    eta_padded = np.zeros((num_jets, max_constits))\n",
        "    phi_padded = np.zeros((num_jets, max_constits))\n",
        "    energy_padded = np.zeros((num_jets, max_constits))\n",
        "    valid_jet_indices = []\n",
        "\n",
        "    for i in range(num_jets):\n",
        "        valid_constits = (pt[i] > 0) & (energy[i] > 0)\n",
        "        pt_valid = pt[i][valid_constits]\n",
        "        eta_valid = eta[i][valid_constits]\n",
        "        phi_valid = phi[i][valid_constits]\n",
        "        energy_valid = energy[i][valid_constits]\n",
        "\n",
        "        num_constits = min(len(pt_valid), max_constits)\n",
        "\n",
        "        if num_constits > 0:\n",
        "            valid_jet_indices.append(i)\n",
        "            eta_valid -= eta_valid[0]\n",
        "            phi_valid = (phi_valid - phi_valid[0] + np.pi) % (2 * np.pi) - np.pi\n",
        "            total_energy = np.sum(energy_valid) + 1e-8\n",
        "            energy_valid /= total_energy\n",
        "            pt_padded[i, :num_constits] = pt_valid[:num_constits]\n",
        "            eta_padded[i, :num_constits] = eta_valid[:num_constits]\n",
        "            phi_padded[i, :num_constits] = phi_valid[:num_constits]\n",
        "            energy_padded[i, :num_constits] = energy_valid[:num_constits]\n",
        "\n",
        "    log_pt = np.log(pt_padded + 1e-8)\n",
        "    preprocessed_data = np.stack([eta_padded, phi_padded, log_pt, energy_padded], axis=-1)\n",
        "    return preprocessed_data, valid_jet_indices\n",
        "\n",
        "preprocessed_data, valid_jet_indices = preprocess(pt_filtered, eta_filtered, phi_filtered, energy_filtered)"
      ],
      "metadata": {
        "id": "F9nQDkwSlGSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Study the effect of the preprocessing**"
      ],
      "metadata": {
        "id": "MjhfoJF1lNi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot multiple jets before and after preprocessing\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Before preprocessing\n",
        "sc1 = axs[0].scatter(eta_filtered.flatten(), phi_filtered.flatten(),\n",
        "                      c=np.log(energy_filtered.flatten() + 1e-8), cmap='viridis', s=10)\n",
        "axs[0].set_title('Jets Before Preprocessing (Log Energy Scale)')\n",
        "axs[0].set_xlabel('$\\eta$')\n",
        "axs[0].set_ylabel('$\\phi$')\n",
        "plt.colorbar(sc1, ax=axs[0], label='Log(Energy)')\n",
        "\n",
        "# After preprocessing\n",
        "sc2 = axs[1].scatter(preprocessed_data[..., 0].flatten(), preprocessed_data[..., 1].flatten(),\n",
        "                      c=np.log(preprocessed_data[..., 3].flatten() + 1e-8), cmap='viridis', s=10)\n",
        "axs[1].set_title('Jets After Preprocessing (Log Normalized Energy Scale)')\n",
        "axs[1].set_xlabel('Preprocessed $\\eta$')\n",
        "axs[1].set_ylabel('Preprocessed $\\phi$')\n",
        "plt.colorbar(sc2, ax=axs[1], label='Log(Normalized Energy)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QvDxpzWLlP9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Creating PyTorch Tensors\n",
        "\n",
        "\n",
        "**What is a Batch?**\n",
        "\n",
        "A **batch** refers to a subset of the dataset that is processed by the neural network at one time during training. Instead of feeding the entire dataset at once, we divide the data into smaller batches, which:\n",
        "- Reduces memory usage.\n",
        "- Allows for efficient computation using parallel hardware (e.g., GPUs).\n",
        "- Provides a smoother gradient update compared to using the entire dataset (stochastic gradient descent).\n",
        "\n",
        "**How are Batches Used?**\n",
        "\n",
        "At each iteration:\n",
        "1. A batch of data is fed into the network.\n",
        "2. The forward pass computes the output for this batch.\n",
        "3. The loss is calculated based on the batch output and true labels.\n",
        "4. The network parameters are updated using backpropagation.\n",
        "\n",
        "In PyTorch, we use the `DataLoader` class to handle batching.\n",
        "\n",
        "* The processed data is converted into PyTorch tensors, which are the primary data structures used for training deep learning models.\n",
        "* A TensorDataset is created, and it is split into training and testing sets using an 80/20 ratio.\n",
        "\n",
        "\n",
        "\n",
        "But first, we need to include the necessary PyTorch packages (https://pytorch.org/)"
      ],
      "metadata": {
        "id": "VoBvAzYZmAYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "#X_tensor = torch.tensor(preprocessed_data, dtype=torch.float32).permute(0, 2, 1).unsqueeze(3)\n",
        "lognorm_energy = preprocessed_data[..., 3]  # 4th feature corresponds to normalized energy\n",
        "\n",
        "# Reshape into a single-channel image (num_samples, 1, eta_bins, phi_bins)\n",
        "X_tensor = torch.tensor(lognorm_energy, dtype=torch.float32).unsqueeze(1)  # Shape: (num_samples, 1, 80, 80)\n",
        "\n",
        "y_tensor = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "NM9GcJTymH7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract eta, phi, and log-normalized energy from preprocessed data\n",
        "eta = preprocessed_data[..., 0]  # eta is the 1st feature\n",
        "phi = preprocessed_data[..., 1]  # phi is the 2nd feature\n",
        "lognorm_energy = preprocessed_data[..., 3]  # log-normalized energy is the 4th feature\n",
        "\n",
        "# Define grid resolution (bins for eta and phi)\n",
        "num_bins = 10\n",
        "eta_min, eta_max = -2, 2\n",
        "phi_min, phi_max = -2, 2\n",
        "\n",
        "# Create grid and fill with log-normalized energy\n",
        "X_images = []\n",
        "for i in range(lognorm_energy.shape[0]):  # Loop over each jet\n",
        "    H, _, _ = np.histogram2d(\n",
        "        eta[i], phi[i], bins=num_bins, range=[[eta_min, eta_max], [phi_min, phi_max]], weights=lognorm_energy[i]\n",
        "    )\n",
        "    X_images.append(H)\n",
        "\n",
        "X_images = np.array(X_images)  # Shape: (num_samples, 80, 80)\n",
        "X_tensor = torch.tensor(X_images, dtype=torch.float32).unsqueeze(1)  # Add channel dimension: (num_samples, 1, 80, 80)\n",
        "\n",
        "y_tensor = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "RLI3eJn7BkID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** Defining the CNN Model\n",
        "\n",
        "Convolutional Neural Networks (CNNs) are commonly used for image-like data. In this case, we treat the constituent features of jets as an image with one channels:\n",
        "\n",
        "- **Input channels**: Each channel corresponds to a preprocessed feature. In this case we only use $E$, normalized with respect to the jet momentum.\n",
        "- **Convolutional layers**: These layers extract spatial patterns from the input.\n",
        "- **Fully connected layers**: These layers combine the extracted features to make the final classification.\n",
        "\n",
        "\n",
        "**General structure of the CNN architecture**\n",
        "1. **Convolutional Layers**: These layers apply filters (kernels) to the input data to extract spatial features.\n",
        "2. **Activation Function (ReLU)**: After each convolution, we apply the ReLU activation function to introduce non-linearity.\n",
        "3. **Pooling Layer**: The pooling layer reduces the spatial dimensions of the feature maps, which helps in reducing computation and preventing overfitting.\n",
        "4. **Fully Connected Layers**: These layers combine the extracted features to make the final classification.\n",
        "5. **Sigmoid Activation**: The output layer uses a sigmoid activation function to produce a probability score between 0 and 1.\n"
      ],
      "metadata": {
        "id": "Mw79VWfLmiaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNJetTagger(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNJetTagger, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), padding=(1, 1))\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=(1, 1))\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * (num_bins // 4) * (num_bins // 4), 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "I-JsAabwmvbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Brief explanation of most important parts of the code:**\n",
        "\n",
        "*nn.Conv2d(in_channels, out_channels, kernel_size, padding)* is a 2D convolutional layer.\n",
        "- in_channels = 1: This means the input image has a single channel (log-normalized energy in your case).\n",
        "- out_channels = 32: The first convolutional layer outputs 32 feature maps by applying 32 different filters.\n",
        "- kernel_size = (3, 3): This specifies that each filter is a 3x3 matrix sliding over the input image.\n",
        "- padding = (1, 1): This adds a padding of 1 pixel around the input to maintain its original size after convolution.\n",
        "\n",
        "*nn.MaxPool2d(kernel_size=(2, 2)):* This is a max-pooling layer that reduces the spatial dimensions of the input by half.\n",
        "- It slides a 2x2 window over the input and takes the maximum value in each window.\n",
        "- This operation helps reduce the computational complexity and extract dominant features.\n",
        "\n",
        "*nn.Flatten():* This layer flattens the 2D feature maps into a 1D vector to be fed into fully connected layers.\n",
        "- If the input to the flatten layer is of shape [batch_size, 64, 20, 20], it will be reshaped to [batch_size, 64 * 20 * 20].\n",
        "\n"
      ],
      "metadata": {
        "id": "K5zFxsytDcFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: GPU or CPU?**\n",
        "\n",
        "The code checks whether a GPU is available using *torch.cuda.is_available()*. If a GPU is found, the model and data are processed on the GPU; otherwise, it falls back to the CPU."
      ],
      "metadata": {
        "id": "b2nkAepxm2Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNNJetTagger().to(device)"
      ],
      "metadata": {
        "id": "z9mqkU7UnERM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization of CNN Architecture**\n",
        "\n",
        "Below is a visualization of the CNN architecture. It shows how data flows through the network, including the convolutional layers, pooling layers, and fully connected layers."
      ],
      "metadata": {
        "id": "2LBkL6q13K0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CNNJetTagger()\n",
        "summary(model, input_size=(1, num_bins, num_bins))"
      ],
      "metadata": {
        "id": "esNO7P1D3OfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes/explanations:**\n",
        "\n",
        "- Input Size (MB): The memory required to store the input data during training.\n",
        "- Forward/Backward Pass Size (MB): The memory used during the forward and backward passes of the neural network.\n",
        "- Params Size (MB): The memory required to store the learnable parameters of the model.\n",
        "- Estimated Total Size (MB): This is the sum of the input size, forward/backward pass size, and parameter size, giving an estimate of the total memory required by the model."
      ],
      "metadata": {
        "id": "F_LrIElA4JEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Training the Model**\n",
        "* The model is trained using binary cross-entropy loss (BCELoss) and the Adam optimizer.\n",
        "* The training loop runs for 10 epochs, and after each epoch, the average loss is recorded and printed.\n",
        "\n",
        "**Loss Function: Binary Cross-Entropy**\n",
        "\n",
        "Since this is a binary classification problem (signal vs. background), we use the **Binary Cross-Entropy Loss**.\n",
        "\n",
        "**Mathematical Definition**\n",
        "The binary cross-entropy loss for a single sample is given by:\n",
        "\n",
        "\n",
        "$\\text{BCE}(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]$\n",
        "\n",
        "Where:\n",
        "- $y$ is the true label $y = 1$ for signal, $y = 0$ for background).\n",
        "- $\\hat{y}$ is the predicted probability of the jet being a signal (output of the network).\n",
        "\n",
        "The total loss over a batch is the mean of individual sample losses:\n",
        "\n",
        "$\\text{Loss}_{\\text{batch}} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{BCE}(y_i, \\hat{y}_i)$\n",
        "\n",
        "In PyTorch, we use the `BCELoss` class to compute this loss automatically.\n"
      ],
      "metadata": {
        "id": "EPL-mYGPnMUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 4\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch).squeeze()\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "8ci_L6wFnY_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Loss vs. epoch:** Shows how well the model is learning over time."
      ],
      "metadata": {
        "id": "cMhRaBOTnSpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, num_epochs + 1), losses, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs. Epoch')\n",
        "plt.grid(True)\n",
        "plt.savefig('loss_vs_epoch.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V1tSUZ5on6eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Performance metrics**\n",
        "\n",
        "After training, the model is evaluated on the test set by generating predictions.\n",
        "* The ROC curve is plotted, showing the trade-off between the true positive rate (TPR) and false positive rate (FPR) at different classification thresholds.\n",
        "* The AUC (Area Under the Curve) is computed to summarize the performance of the model.\n",
        "\n",
        "Skickit learn is a very useful package for such operations"
      ],
      "metadata": {
        "id": "1VYVuBgeoA3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch).cpu().numpy()\n",
        "        y_true.extend(y_batch.numpy())\n",
        "        y_pred.extend(outputs)"
      ],
      "metadata": {
        "id": "phnZgxDSoAWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_true and y_pred to numpy arrays and flatten them\n",
        "y_true = np.array(y_true).flatten()\n",
        "y_pred = np.array(y_pred).flatten()\n",
        "\n",
        "# Separate output scores for signal (y_true = 1) and background (y_true = 0)\n",
        "y_pred_signal = y_pred[y_true == 1]\n",
        "y_pred_background = y_pred[y_true == 0]\n",
        "\n",
        "# Plot histograms for signal and background\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Histogram of output scores for signal events\n",
        "plt.hist(y_pred_signal, bins=50, alpha=0.7, label='Signal (True Class = 1)', color='blue', density=True)\n",
        "\n",
        "# Histogram of output scores for background events\n",
        "plt.hist(y_pred_background, bins=50, alpha=0.7, label='Background (True Class = 0)', color='red', density=True)\n",
        "\n",
        "plt.xlabel('Output Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Output Score Distributions for Signal and Background')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uxtqp4A_oTU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(tpr, fpr, label=f'CNN-2D (AUC = {roc_auc:.3f})', lw=2)\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)\n",
        "plt.xlabel('True Positive Rate (TPR)')\n",
        "plt.ylabel('False Positive Rate (FPR)')\n",
        "plt.title('ROC Curve for CNN-2D Jet Tagging')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.savefig('roc_curve_cnn2d.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o6rb6-OmokIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Graph Neural Network-based algorithm**"
      ],
      "metadata": {
        "id": "20FB_S9urDkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0:** Include tools *pytorch_ geometric* that can make the development of GNNs very straight forward"
      ],
      "metadata": {
        "id": "b3RICSuVrYAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "-aONuVCIrjOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Preprocessing for GNN\n",
        "\n",
        "Before feeding the data into a Graph Neural Network (GNN), it is essential to prepare the data in a way that is suitable for graph-based learning. Unlike the CNN preprocessing (where we used centering, rotation, and normalization), the preprocessing for GNN focuses on scaling and normalizing the features of the nodes to ensure that the network can efficiently learn patterns without being biased by large variations in feature magnitudes.\n",
        "\n",
        "In this step, we:\n",
        "1.\tPad the number of constituents for each jet to a fixed size (max_constits) to ensure uniform input shapes.\n",
        "2.\tScale each feature (transverse momentum, pseudorapidity, azimuthal angle, and energy) so that they have zero mean and unit variance. This step improves the stability of the training process and ensures that features contribute equally to the learning process."
      ],
      "metadata": {
        "id": "CR9nTIIHrp-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def preprocess_for_GNN(pt, eta, phi, energy, max_constits=80):\n",
        "    \"\"\"\n",
        "    Preprocess the input data for GNN by:\n",
        "    1. Padding to ensure a uniform number of constituents per jet.\n",
        "    2. Scaling each feature to have zero mean and unit variance.\n",
        "    \"\"\"\n",
        "    num_jets = len(pt)\n",
        "\n",
        "    # Initialize padded arrays\n",
        "    pt_padded = np.zeros((num_jets, max_constits))\n",
        "    eta_padded = np.zeros((num_jets, max_constits))\n",
        "    phi_padded = np.zeros((num_jets, max_constits))\n",
        "    energy_padded = np.zeros((num_jets, max_constits))\n",
        "\n",
        "    for i in range(num_jets):\n",
        "        num_constits = min(len(pt[i]), max_constits)\n",
        "        pt_padded[i, :num_constits] = pt[i][:num_constits]\n",
        "        eta_padded[i, :num_constits] = eta[i][:num_constits]\n",
        "        phi_padded[i, :num_constits] = phi[i][:num_constits]\n",
        "        energy_padded[i, :num_constits] = energy[i][:num_constits]\n",
        "\n",
        "    # Normalize each feature to have zero mean and unit variance\n",
        "    pt_scaled = (pt_padded - np.mean(pt_padded)) / np.std(pt_padded)\n",
        "    eta_scaled = (eta_padded - np.mean(eta_padded)) / np.std(eta_padded)\n",
        "    phi_scaled = (phi_padded - np.mean(phi_padded)) / np.std(phi_padded)\n",
        "    energy_scaled = (energy_padded - np.mean(energy_padded)) / np.std(energy_padded)\n",
        "\n",
        "    return pt_scaled, eta_scaled, phi_scaled, energy_scaled"
      ],
      "metadata": {
        "id": "xICP9xzRd_1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Creating the Graph\n",
        "\n",
        "In this step, we convert the jets into graphs, where:\n",
        "*\tEach constituent becomes a node in the graph.\n",
        "*\tEdges are created between all pairs of nodes, forming a fully connected graph.\n",
        "*\tNode features are represented by the four attributes: transverse momentum (pt), pseudorapidity ($\\eta$), azimuthal angle ($\\phi$), and energy.\n",
        "\n",
        "\n",
        "A more technical explanation:\n",
        "1.\tNode Features: Each constituent is treated as a node with four features: [pt, eta, phi, energy].\n",
        "2.\tEdges: We assume a fully connected graph, where each node is connected to every other node. This is achieved using torch.combinations.\n",
        "3.\tGraph Labels: Each graph (jet) is assigned a label indicating whether it belongs to the background class (0) or signal class (1).\n",
        "4.\tPyTorch Geometric Data Object: Each graph is represented as a Data object from PyTorch Geometric, which stores the node features, edge information, and labels."
      ],
      "metadata": {
        "id": "rPD2ceyert9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graph_data(pt, eta, phi, energy, labels):\n",
        "    \"\"\"\n",
        "    Convert the jet constituents into graph data.\n",
        "    Each constituent becomes a node, and edges are created as fully connected.\n",
        "    \"\"\"\n",
        "    data_list = []\n",
        "    num_samples = pt.shape[0]\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        num_constituents = pt[i].shape[0]\n",
        "\n",
        "        # Create node features: [pt, eta, phi, energy]\n",
        "        x = torch.tensor(np.stack([pt[i], eta[i], phi[i], energy[i]], axis=-1), dtype=torch.float32)\n",
        "\n",
        "        # Fully connected graph (edges between all constituents)\n",
        "        edge_index = torch.combinations(torch.arange(num_constituents), r=2).t()\n",
        "\n",
        "        # Label for the graph\n",
        "        y = torch.tensor(labels[i], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        # Create Data object for PyTorch Geometric\n",
        "        graph = Data(x=x, edge_index=edge_index, y=y)\n",
        "        data_list.append(graph)\n",
        "\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "r456P-cvrUUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Defining the GNN Model\n",
        "\n",
        "The GNN model consists of:\n",
        "1.\tGraph convolutional layers (GCNConv), which aggregate information from neighboring nodes.\n",
        "2.\tGlobal mean pooling, which aggregates node features into a graph-level representation.\n",
        "3.\tFully connected layers, which process the graph-level representation and output a probability for binary classification."
      ],
      "metadata": {
        "id": "E28D4vmGr3av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNJetTagger(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNJetTagger, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels=4, out_channels=32)\n",
        "        self.conv2 = GCNConv(in_channels=32, out_channels=64)\n",
        "        self.fc1 = nn.Linear(64, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        \"\"\"\n",
        "        Forward pass for the GNN model:\n",
        "        1. Apply two graph convolutional layers with ReLU activation.\n",
        "        2. Use global mean pooling to aggregate node features into a graph-level representation.\n",
        "        3. Pass the graph representation through fully connected layers.\n",
        "        4. Apply sigmoid activation to output a probability for binary classification.\n",
        "        \"\"\"\n",
        "        x = torch.relu(self.conv1(x, edge_index))\n",
        "        x = torch.relu(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)  # Global pooling\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "fckPEGyErxVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The most important part of the above code: The GCN Layer**\n",
        "\n",
        "A GCN layer applies the following operation:\n",
        "\n",
        "\n",
        "$h_i^{(l+1)} = \\sigma \\left( \\sum_{j \\in \\mathcal{N}(i)} \\frac{1}{\\sqrt{d_i d_j}} W^{(l)} h_j^{(l)} + b^{(l)} \\right)$\n",
        "\n",
        "\n",
        "Where:\n",
        "- $h_i^{(l)}$  is the feature vector of node  $i$  at layer  $l$\n",
        "- $\\mathcal{N}(i)$  is the set of neighbors of node  $i$\n",
        "- $d_i$  is the degree of node  $i$  (number of neighbors)\n",
        "- $W^{(l)}$  and  $b^{(l)}$  are the learnable weight matrix and bias vector for layer  $l$\n",
        "- $\\sigma$  is the activation function (ReLU in this case).\n"
      ],
      "metadata": {
        "id": "9mlRgpGwEZLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build and Visualize the graphs**"
      ],
      "metadata": {
        "id": "0Dj3VFnEFd22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "max_constits = 80\n",
        "pt_scaled, eta_scaled, phi_scaled, energy_scaled = preprocess_for_GNN(pt_filtered, eta_filtered, phi_filtered, energy_filtered, max_constits)\n",
        "data_list = create_graph_data(pt_scaled, eta_scaled, phi_scaled, energy_scaled, labels)\n",
        "\n",
        "# Find indices for signal and background graphs\n",
        "signal_indices = [i for i, data in enumerate(data_list) if data.y.item() == 1]\n",
        "background_indices = [i for i, data in enumerate(data_list) if data.y.item() == 0]\n",
        "\n",
        "# Select one signal and one background graph for visualization\n",
        "signal_graph = data_list[signal_indices[0]]\n",
        "background_graph = data_list[background_indices[0]]\n",
        "\n",
        "# Convert to NetworkX format for visualization\n",
        "signal_nx = to_networkx(signal_graph, node_attrs=['x'], edge_attrs=None)\n",
        "background_nx = to_networkx(background_graph, node_attrs=['x'], edge_attrs=None)\n",
        "\n",
        "# Plot signal graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw(signal_nx, with_labels=False, node_size=50, node_color='red')\n",
        "plt.title('Signal Graph')\n",
        "plt.show()\n",
        "\n",
        "# Plot background graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw(background_nx, with_labels=False, node_size=50, node_color='blue')\n",
        "plt.title('Background Graph')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HK6T5JOLEPiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Preparing Data for Training"
      ],
      "metadata": {
        "id": "HSSz6OTZr9AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_size = int(0.8 * len(data_list))\n",
        "test_size = len(data_list) - train_size\n",
        "train_data, test_data = torch.utils.data.random_split(data_list, [train_size, test_size])\n",
        "\n",
        "# Create DataLoader for training and testing\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "rSg-4Xpur6Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** Train the GNN Model"
      ],
      "metadata": {
        "id": "8pDNNxQSsCko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GNNJetTagger().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 4\n",
        "losses = []  # List to store the average loss for each epoch\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0  # Initialize running loss for the epoch\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)  # Move the batch to the selected device (CPU/GPU)\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        outputs = model(batch.x, batch.edge_index, batch.batch).squeeze()  # Forward pass\n",
        "        loss = criterion(outputs, batch.y)  # Compute the binary cross-entropy loss\n",
        "        loss.backward()  # Backpropagation (compute gradients)\n",
        "        optimizer.step()  # Update the model's parameters\n",
        "        running_loss += loss.item()  # Accumulate loss for the epoch\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)  # Compute average loss for the epoch\n",
        "    losses.append(avg_loss)  # Store the average loss for plotting\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dKR1graJvR74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss vs. epoch curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, num_epochs + 1), losses, marker='o', color='blue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs. Epoch for GNN')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wqHbYs7BwrE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6:** Evaluate the GNN Model"
      ],
      "metadata": {
        "id": "cMSUX168sIoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        outputs = model(batch.x, batch.edge_index, batch.batch).cpu().numpy()\n",
        "        y_true.extend(batch.y.cpu().numpy())\n",
        "        y_pred.extend(outputs)"
      ],
      "metadata": {
        "id": "K6g8HHr-tZKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_true and y_pred to numpy arrays and flatten them\n",
        "y_true = np.array(y_true).flatten()\n",
        "y_pred = np.array(y_pred).flatten()\n",
        "\n",
        "# Separate output scores for signal (y_true = 1) and background (y_true = 0)\n",
        "y_pred_signal = y_pred[y_true == 1]\n",
        "y_pred_background = y_pred[y_true == 0]\n",
        "\n",
        "# Plot histograms for signal and background\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Histogram of output scores for signal events\n",
        "plt.hist(y_pred_signal, bins=50, alpha=0.7, label='Signal (True Class = 1)', color='blue', density=True)\n",
        "\n",
        "# Histogram of output scores for background events\n",
        "plt.hist(y_pred_background, bins=50, alpha=0.7, label='Background (True Class = 0)', color='red', density=True)\n",
        "\n",
        "plt.xlabel('Output Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Output Score Distributions for Signal and Background')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KNPTO8x8tVs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(tpr, fpr, label=f'GNN (AUC = {roc_auc:.3f})', lw=2)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('True Positive Rate')\n",
        "plt.ylabel('False Positive Rate')\n",
        "plt.title('ROC Curve for GNN Jet Tagging')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MPB1MnbpsFzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnb91tpYsMOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}